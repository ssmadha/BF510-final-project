{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be25fb9",
   "metadata": {},
   "source": [
    "This notebook details downloading the datasets and preparing it for the later model fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c9e07f",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6f6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import urllib3\n",
    "import re\n",
    "import pickle\n",
    "import progressbar\n",
    "import ftplib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df20846",
   "metadata": {},
   "source": [
    "Searched Pubmed Central for \"algorithmic bias\" and filtered for articles that are fully freely accessible on pubmed. The list of pmc's was then exported to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b08968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcs = list()\n",
    "with open(\"pmc_result_algorithmicbias.txt\") as f:\n",
    "    for pmc in f.readlines():\n",
    "        pmcs.append(pmc.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461ff5d",
   "metadata": {},
   "source": [
    "Downloaded a table with the FTP information on all freely accessible articles on PMC from https://ftp.ncbi.nlm.nih.gov/pub/pmc/oa_file_list.txt, which is loaded into python below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddc7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_files = pd.read_table(\"oa_file_list.txt\", sep='\\t', \n",
    "                         names=[\"ftppath\",\"source\",\"PMCID\",\"PMID\",\"Copyright\"], \n",
    "                        skiprows=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d761d7e",
   "metadata": {},
   "source": [
    "Download the articles from the list using FTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173f4db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (571 of 10322) |#                   | Elapsed Time: 0:05:16 ETA:   5:56:59"
     ]
    }
   ],
   "source": [
    "bar = progressbar.ProgressBar(max_value=len(pmcs))\n",
    "i=0\n",
    "erroredpmcs = list()\n",
    "for pmc in pmcs:\n",
    "    if not os.path.exists(\"papers/\" + pmc + \".tar.gz\"):\n",
    "        try:\n",
    "            ftp = ftplib.FTP(\"ftp.ncbi.nlm.nih.gov\")\n",
    "            ftp.login()\n",
    "            ftp.cwd(\"pub/pmc\")\n",
    "\n",
    "            with open(\"papers/\" + pmc + \".tar.gz\", 'wb') as f:\n",
    "                ftp.retrbinary(\"RETR \" + \n",
    "                               oa_files.loc[oa_files[\"PMCID\"]==pmc, \"ftppath\"].values[0],\n",
    "                              f.write)\n",
    "            ftp.quit()\n",
    "        except:\n",
    "            erroredpmcs.append(pmc)\n",
    "    i+=1\n",
    "    bar.update(i)\n",
    "\n",
    "#ftp.retrlines(\"LIST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae540204",
   "metadata": {},
   "source": [
    "This should be run on a unix command line, extract article XMLs from the downloaded tarballs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1f6d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run on command line:\n",
    "#for var in *.tar.gz\n",
    "#do\n",
    "#  tar -xf $var\n",
    "#  cp ${var/.tar.gz/}/*xml xmls/${var/.tar.gz/.nxml}\n",
    "#  tar -czf $var ${var/.tar.gz}/\n",
    "#  rm -r ${var/.tar.gz}\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b46c93",
   "metadata": {},
   "source": [
    "A function to remove other article references and figure and table references, to allow the text to conform better to natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de0a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    '''\n",
    "    Remove anything in [], generally reference numbers\n",
    "    Also, remove figure and table references\n",
    "    '''\n",
    "    newdata = re.sub(\" ?\\[.*\\]\", '', data)\n",
    "    newdata = re.sub(\" ?\\(Fig.*\\)\", '', newdata)\n",
    "    newdata = re.sub(\" ?\\(Table.*\\)\", '', newdata)\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb6336",
   "metadata": {},
   "source": [
    "Read in each of the files and attempt to parse them into python dictionaries. Included all common sections of papers except for methods, references, and supplementary information so as to provide the most natural type of language to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939384e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (10309 of 10322) |################# | Elapsed Time: 0:00:43 ETA:   0:00:00"
     ]
    }
   ],
   "source": [
    "relevantSections = np.array([\"title\",\"abstract\", \"introduction\", \"result\", \"discussion\", \"conclusion\"])\n",
    "bar = progressbar.ProgressBar(max_value=len(pmcs))\n",
    "i=0\n",
    "articles = dict()\n",
    "for pmc in pmcs:\n",
    "    if not os.path.exists(\"papers/xmls/\" + pmc + \".nxml\"):\n",
    "        i+=1\n",
    "        continue\n",
    "    article = {x:\"\" for x in relevantSections}\n",
    "    try:\n",
    "        root = ET.parse(\"papers/xmls/\" + pmc + \".nxml\").getroot()\n",
    "    except:\n",
    "        print(pmc)\n",
    "        i+=1\n",
    "        continue\n",
    "    article[\"title\"] = root.find(\"front\").find(\"article-meta\").find(\"title-group\").findtext(\"article-title\")\n",
    "    if root.find(\"front\").find(\"article-meta\").find(\"abstract\"):\n",
    "        if root.find(\"front\").find(\"article-meta\").find(\"abstract\").find(\"sec\")\\\n",
    "        and root.find(\"front\").find(\"article-meta\").find(\"abstract\").find(\"sec\").find(\"p\"):\n",
    "            if root.find(\"front\").find(\"article-meta\").find(\"abstract\").find(\"sec\").find(\"sec\"):\n",
    "                article[\"abstract\"] = \" \".join([sec.findtext(\"p\") \n",
    "                                                for sec in root.find(\"front\").find(\"article-meta\").find(\"abstract\").find(\"sec\").findall(\"sec\")])\n",
    "            else:\n",
    "                article[\"abstract\"] = \" \".join([sec.findtext(\"p\") \n",
    "                                                for sec in root.find(\"front\").find(\"article-meta\").find(\"abstract\").findall(\"sec\")])\n",
    "        else:\n",
    "            article[\"abstract\"] = root.find(\"front\").find(\"article-meta\").find(\"abstract\").findtext(\"p\")\n",
    "    if not root.find(\"body\"):\n",
    "        i+=1\n",
    "        continue\n",
    "    for x in root.find(\"body\").findall(\"sec\"):\n",
    "        sec = x.findtext(\"title\")\n",
    "        if not sec or not any(section in sec.lower() for section in relevantSections):\n",
    "            continue\n",
    "        for section in relevantSections:\n",
    "            if section in sec.lower():\n",
    "                sec = section\n",
    "        article[sec] = \"\"\n",
    "        for y in x.iter(\"p\"):\n",
    "            text = clean_data(\"\".join(y.itertext()))\n",
    "            article[sec] += text\n",
    "    articles[pmc] = article\n",
    "    bar.update(i)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21b03c",
   "metadata": {},
   "source": [
    "Save the processed articles to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8680193",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"articles.obj\", 'wb') as f:\n",
    "    pickle.dump(articles, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
